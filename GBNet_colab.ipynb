{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GBNet_colab.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNYKBmp5o+SSfAi4LjiN377",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIPTE/Deep-Geometry-Learning-on-Colab/blob/master/GBNet_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndm_-V0Fhw6v",
        "outputId": "bcf72470-8558-4960-ae30-f3b6dcfc1f5c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t gbnet.png  main.py   pretrained  util.py\n",
            "data.py  LICENSE    model.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oXUJlUth1Dx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6CDzt-Ih5ha"
      },
      "source": [
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pthh_d44h94t"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive')#切换工作目录"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWB2fF8xiBaZ",
        "outputId": "6e145643-08f5-4a3a-8182-05b2b7202088"
      },
      "source": [
        "!git clone https://github.com/ShiQiu0419/GBNet.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GBNet'...\n",
            "remote: Enumerating objects: 510, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 510 (delta 90), reused 0 (delta 0), pack-reused 347\u001b[K\n",
            "Receiving objects: 100% (510/510), 906.68 KiB | 6.08 MiB/s, done.\n",
            "Resolving deltas: 100% (289/289), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rks0NvqfiE-u"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/GBNet')#切换工作目录"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr4VilZritCJ",
        "outputId": "fac1e14c-dae6-476a-94d5-76f47ee61390"
      },
      "source": [
        "!python main.py --exp_name=gbnet_modelnet40 --model=gbnet --dataset=modelnet40"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=16, dataset='modelnet40', dropout=0.5, emb_dims=1024, epochs=300, eval=False, exp_name='gbnet_modelnet40', k=20, lr=0.001, model='gbnet', model_path='', momentum=0.9, no_cuda=False, num_points=1024, seed=1, test_batch_size=8, use_sgd=True)\n",
            "Using GPU : 0 from 1 devices\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "GBNet(\n",
            "  (abem1): ABEM_Module(\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(28, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv2d(64, 14, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv2d(28, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa1): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv2d(28, 64, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa2): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (abem2): ABEM_Module(\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa1): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa2): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (abem3): ABEM_Module(\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa1): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa2): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (abem4): ABEM_Module(\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa1): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "    (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv4): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(1, 20), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (caa2): CAA_Module(\n",
            "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (query_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (key_conv): Sequential(\n",
            "        (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (value_conv): Sequential(\n",
            "        (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
            "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "      )\n",
            "      (softmax): Softmax(dim=-1)\n",
            "    )\n",
            "  )\n",
            "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv): Sequential(\n",
            "    (0): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (caa): CAA_Module(\n",
            "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (query_conv): Sequential(\n",
            "      (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (key_conv): Sequential(\n",
            "      (0): Conv1d(1024, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (value_conv): Sequential(\n",
            "      (0): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (softmax): Softmax(dim=-1)\n",
            "  )\n",
            "  (linear1): Linear(in_features=2048, out_features=512, bias=False)\n",
            "  (bn_linear1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp1): Dropout(p=0.5, inplace=False)\n",
            "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (bn_linear2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dp2): Dropout(p=0.5, inplace=False)\n",
            "  (linear3): Linear(in_features=256, out_features=40, bias=True)\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Use SGD\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Train 0, loss: 3.413386, train acc: 0.182825, train avg acc: 0.078436\n",
            "Test 0, loss: 2.932748, test acc: 0.311994, test avg acc: 0.199703\n",
            "Current Best: 0.311994\n",
            "Train 1, loss: 2.764883, train acc: 0.406098, train avg acc: 0.221159\n",
            "Test 1, loss: 2.452361, test acc: 0.502026, test avg acc: 0.337605\n",
            "Current Best: 0.502026\n",
            "Train 2, loss: 2.503907, train acc: 0.507622, train avg acc: 0.315264\n",
            "Test 2, loss: 2.258494, test acc: 0.594003, test avg acc: 0.450808\n",
            "Current Best: 0.594003\n",
            "Train 3, loss: 2.356176, train acc: 0.580285, train avg acc: 0.393342\n",
            "Test 3, loss: 2.174992, test acc: 0.621556, test avg acc: 0.471948\n",
            "Current Best: 0.621556\n",
            "Train 4, loss: 2.267323, train acc: 0.611484, train avg acc: 0.436177\n",
            "Test 4, loss: 2.057015, test acc: 0.675041, test avg acc: 0.566640\n",
            "Current Best: 0.675041\n",
            "Train 5, loss: 2.178280, train acc: 0.646646, train avg acc: 0.477501\n",
            "Test 5, loss: 1.997633, test acc: 0.720016, test avg acc: 0.598017\n",
            "Current Best: 0.720016\n",
            "Train 6, loss: 2.122394, train acc: 0.672764, train avg acc: 0.510510\n",
            "Test 6, loss: 1.958942, test acc: 0.757293, test avg acc: 0.670616\n",
            "Current Best: 0.757293\n",
            "Train 7, loss: 2.072175, train acc: 0.696037, train avg acc: 0.539509\n",
            "Test 7, loss: 1.854882, test acc: 0.791734, test avg acc: 0.662884\n",
            "Current Best: 0.791734\n",
            "Train 8, loss: 2.017335, train acc: 0.718496, train avg acc: 0.572525\n",
            "Test 8, loss: 1.823442, test acc: 0.799028, test avg acc: 0.704622\n",
            "Current Best: 0.799028\n",
            "Train 9, loss: 1.979884, train acc: 0.734959, train avg acc: 0.600574\n",
            "Test 9, loss: 1.831133, test acc: 0.814425, test avg acc: 0.721895\n",
            "Current Best: 0.814425\n",
            "Train 10, loss: 1.937857, train acc: 0.755691, train avg acc: 0.626574\n",
            "Test 10, loss: 1.757857, test acc: 0.820097, test avg acc: 0.721971\n",
            "Current Best: 0.820097\n",
            "Train 11, loss: 1.916753, train acc: 0.767073, train avg acc: 0.650105\n",
            "Test 11, loss: 1.745215, test acc: 0.824149, test avg acc: 0.733215\n",
            "Current Best: 0.824149\n",
            "Train 12, loss: 1.893923, train acc: 0.776220, train avg acc: 0.657118\n",
            "Test 12, loss: 1.731292, test acc: 0.826175, test avg acc: 0.741698\n",
            "Current Best: 0.826175\n",
            "Train 13, loss: 1.863656, train acc: 0.786789, train avg acc: 0.673309\n",
            "Test 13, loss: 1.724259, test acc: 0.841572, test avg acc: 0.742174\n",
            "Current Best: 0.841572\n",
            "Train 14, loss: 1.853008, train acc: 0.794411, train avg acc: 0.683789\n",
            "Test 14, loss: 1.727891, test acc: 0.839141, test avg acc: 0.775424\n",
            "Train 15, loss: 1.838954, train acc: 0.794919, train avg acc: 0.691017\n",
            "Test 15, loss: 1.685374, test acc: 0.838331, test avg acc: 0.779988\n",
            "Train 16, loss: 1.813075, train acc: 0.810467, train avg acc: 0.710998\n",
            "Test 16, loss: 1.674841, test acc: 0.855754, test avg acc: 0.781959\n",
            "Current Best: 0.855754\n",
            "Train 17, loss: 1.807557, train acc: 0.813008, train avg acc: 0.716060\n",
            "Test 17, loss: 1.691842, test acc: 0.855754, test avg acc: 0.782477\n",
            "Current Best: 0.855754\n",
            "Train 18, loss: 1.802367, train acc: 0.810976, train avg acc: 0.711533\n",
            "Test 18, loss: 1.694035, test acc: 0.856564, test avg acc: 0.775285\n",
            "Current Best: 0.856564\n",
            "Train 19, loss: 1.788890, train acc: 0.822053, train avg acc: 0.730977\n",
            "Test 19, loss: 1.666976, test acc: 0.855754, test avg acc: 0.798029\n",
            "Train 20, loss: 1.770081, train acc: 0.829776, train avg acc: 0.738647\n",
            "Test 20, loss: 1.670793, test acc: 0.854943, test avg acc: 0.779465\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}